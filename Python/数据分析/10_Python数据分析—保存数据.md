---
title: Python数据分析—保存数据
tags:
  - Python
categories:
  - Python
---

当完成数据清洗后，可以把干净整洁的版本先保存一下，假如会进行多次数据分析，可以有效节约下一次分析的时间，因为不需要再重复评估和清洗步骤了。

保存数据，本质上就是把DataFrame，写入到一个新建的空白文件里。

## 写入CSV文件

DataFrame的`to_csv`方法，参数传入文件路径，调用后就能把DataFrame转换成CSV格式，并且保存在路径对应的文件里面。

**如果那个文件本身不存在，新文件会自动帮我们创建出来；**

**但如果路径对应的文件已经存在，方法运行后，就会把原始内容给覆盖掉。**

`to_csv`方法，会默认把DataFrame的列名和索引都写入到文件里

```python
import pandas as pd
import numpy as np

# 创建示例 DataFrame
df1 = pd.DataFrame({
    '日期': ['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-04'],
    '销售额': [1000, 1500, 800, 1200],
    '销售人员': ['Alice', 'Bob', 'Charlie', 'David'],
    '城市': ['New York', 'San Francisco', 'New York', 'San Francisco']
})
df1 = df1.rename(index={
    0: '38H9',
    1: 'W9F1',
    2: 'KD82',
    3: '004U'
})
df1
```

|          | **日期**   | **销售额** | **销售人员** | **城市**      |
| -------- | :--------- | :--------- | :----------- | :------------ |
| **38H9** | 2022-01-01 | 1000       | Alice        | New York      |
| **W9F1** | 2022-01-02 | 1500       | Bob          | San Francisco |
| **KD82** | 2022-01-03 | 800        | Charlie      | New York      |
| **004U** | 2022-01-04 | 1200       | David        | San Francisco |




```python
df1.to_csv('cleaned_sales_data.csv')
cleaned_df = pd.read_csv('cleaned_sales_data.csv')
cleaned_df
```

|       | **Unnamed: 0** | **日期**   | **销售额** | **销售人员** | **城市**      |
| ----- | :------------- | :--------- | :--------- | :----------- | :------------ |
| **0** | 38H9           | 2022-01-01 | 1000       | Alice        | New York      |
| **1** | W9F1           | 2022-01-02 | 1500       | Bob          | San Francisco |
| **2** | KD82           | 2022-01-03 | 800        | Charlie      | New York      |
| **3** | 004U           | 2022-01-04 | 1200       | David        | San Francisco |


以上运行结果是因为，to_csv方法会默认帮我们把索引进行保存，但读取的时候，read_csv不知道那是索引，所以它们又被当成了第一列数据，而且因为这列上面没有名字，列名变成Unnamed: 0，表示那是没有名字的第一列。

调整方法

### 1、默认to_csv和read_csv后

先调用清理数据中所学的rename方法，给列换一个有意义的名字

```python
cleaned_df.rename(columns={'Unnamed: 0': '销售ID'}, inplace=True)
cleaned_df
```

|       | **销售ID** | **日期**   | **销售额** | **销售人员** | **城市**      |
| ----- | :--------- | :--------- | :--------- | :----------- | :------------ |
| **0** | 38H9       | 2022-01-01 | 1000       | Alice        | New York      |
| **1** | W9F1       | 2022-01-02 | 1500       | Bob          | San Francisco |
| **2** | KD82       | 2022-01-03 | 800        | Charlie      | New York      |
| **3** | 004U       | 2022-01-04 | 1200       | David        | San Francisco |


然后调用`set_index`方法，把那一列设置为DataFrame的索引

```python
cleaned_df.set_index('销售ID', inplace=True)
cleaned_df
```

|            | **日期**   | **销售额** | **销售人员** | **城市**      |
| ---------- | ---------- | ---------- | ------------ | ------------- |
| **销售ID** |            |            |              |               |
| **38H9**   | 2022-01-01 | 1000       | Alice        | New York      |
| **W9F1**   | 2022-01-02 | 1500       | Bob          | San Francisco |
| **KD82**   | 2022-01-03 | 800        | Charlie      | New York      |
| **004U**   | 2022-01-04 | 1200       | David        | San Francisco |


### 2、写入CSV文件时，不保存DataFrame的索引

to_csv方法，放入可选参数`index=False`，写入时会自动忽略索引

**如果DataFrame的索引，只是位置索引，一般我们不会专门写入，也就是说会指定**`**index=False**`**；但如果是有关键信息的标签索引，就写入到CSV文件里**

```python
df1.to_csv('cleaned_sales_data2.csv', index=False)
cleaned_df_without_index = pd.read_csv('cleaned_sales_data2.csv')
cleaned_df_without_index
```

|       | **日期**   | **销售额** | **销售人员** | **城市**      |
| ----- | :--------- | :--------- | :----------- | :------------ |
| **0** | 2022-01-01 | 1000       | Alice        | New York      |
| **1** | 2022-01-02 | 1500       | Bob          | San Francisco |
| **2** | 2022-01-03 | 800        | Charlie      | New York      |
| **3** | 2022-01-04 | 1200       | David        | San Francisco |


### 3、可选参数index_col=0

读取CSV文件时，放入可选参数`index_col=0`，表示把CSV第一列数据作为索引

```python
cleaned_df2 = pd.read_csv('cleaned_sales_data.csv', index_col=0)
cleaned_df2
```

|          | **日期**   | **销售额** | **销售人员** | **城市**      |
| -------- | :--------- | :--------- | :----------- | :------------ |
| **38H9** | 2022-01-01 | 1000       | Alice        | New York      |
| **W9F1** | 2022-01-02 | 1500       | Bob          | San Francisco |
| **KD82** | 2022-01-03 | 800        | Charlie      | New York      |
| **004U** | 2022-01-04 | 1200       | David        | San Francisco |




## 数据评估和清洗整体流程

**下载数据；**

**读取数据；**

**评估数据；**

**根据对数据的评估，指定清洗的步骤；清洗数据；每清洗一步，就再次查看清洗后的数据，来确保问题已经解决；**

**保存清洗后的数据**

在Jupyter Notebook里进行数据清晰，并以报告的形式呈现内容。

运用标题，使内容结构清晰；

运用Markdown对代码进行注释，方便读者理解；

并且运用Markdown，总结评估结论，使内容逻辑清晰。

### 1、下载数据

1. 每次清洗数据项目开始前，都新建一个新的文件夹，将数据文件和Jupyter Notebook放入。

这样可以保持文件结构的整洁；数据文件和Jupyter Notebook放入同一文件夹，也方便读取

1. 对于公开数据集，我们并不了解它的背景，在正式分析前，最好了解一下它的介绍，和数据每列的含义。

### 2、读取数据

### 3、评估数据 

#### 1）缺失数据

发现缺失数据后，需要深入探索缺失数据：应把该变量存在缺失的观察值，筛选出来，进一步观察数据特征，(提出猜测，验证猜测)

#### 2）重复数据

首先判断哪些变量不应该重复，再去评估数据。

**唯一标识符不一定不能重复，具体数据具体分析**

#### 3）不一致数据

先观察哪个变量可以判断是否存在不一致数据，再去评估数据。

#### 4）无效/错误数据

先观察哪个变量可以判断是否存在不一致数据。

然后通过某些方法，结合常识，评估无效/错误数据。

最后，与缺失数据一样，发现无效/错误数据后，需要深入探索无效/错误数据：应把该变量无效/错误的观察值，筛选出来，进一步观察数据特征，(提出猜测，验证猜测)

### 4、根据对数据的评估，指定清洗的步骤

#### 清洗数据

1. 在清洗前，先创建一个新变量，用于储存清洗过程中的数据。

这样原始的数据和经过清理的数据，分别储存在两个变量中

2. 清洗数据过程中，遇到现学处理方法无法很好清理数据的情况，可以查询官方文档或查询搜索引擎。

#### 每清洗一步，就再次查看清洗后的数据，来确保问题已经解决

### 5、保存清洗后的数据

新的CSV文件名，可以是在原始CSV文件名后面，添加`'_cleaned'`。



## 分享到GitHub

Notebook文件格式不方便直接分享

用文本编辑器打开，文本内容并不直观，也不可读。

notebook文件需要用Jupyter Notebook或代码编辑器打开；或者把notebook上传到GitHub，然后分享项目链接，因为GitHub能直接渲染Notebook的内容并进行展示。

GitHub是世界上最大的代码托管网站，和开源社区。可以在上面管理代码和追踪代码历史记录，也可以在上面搜索和查看无数其它开发者的项目代码

### (一)、创建代码仓库

1. license

也就是软件许可证，是用来规定和限制用户，使用这个仓库里面的代码的权利的。

不同许可证的含义：[https://choosealicense.com/](https://choosealicense.com/)

### (二)、Git

1. Git是GitHub背后的版本控制系统，git可以记录项目每次做了什么改动，是由谁改动的，也可以随时切换到之前某个版本的状态
2. 学习Git命令：[https://www.runoob.com/git/git-tutorial.html](https://www.runoob.com/git/git-tutorial.html)

